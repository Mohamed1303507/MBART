{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ldl0PP3HF2DR",
        "outputId": "200e23c3-dd30-42bc-c012-9e882900997e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: arabert in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: PyArabic in /usr/local/lib/python3.10/dist-packages (from arabert) (0.6.15)\n",
            "Requirement already satisfied: farasapy in /usr/local/lib/python3.10/dist-packages (from arabert) (0.0.14)\n",
            "Requirement already satisfied: emoji==1.4.2 in /usr/local/lib/python3.10/dist-packages (from arabert) (1.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from farasapy->arabert) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from farasapy->arabert) (4.65.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from PyArabic->arabert) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy->arabert) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy->arabert) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy->arabert) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy->arabert) (3.4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece\n",
        "!pip install transformers\n",
        "!pip install transformers torch\n",
        "!pip install rouge\n",
        "!pip install arabert\n",
        "# Import necessary libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import torch\n",
        "import pandas as pd\n",
        "import re\n",
        "import regex\n",
        "from tqdm import tqdm\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from transformers import MBartForConditionalGeneration, MBartTokenizer\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Mount Google Drive if using Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to your labeled validation dataset\n",
        "file_path = \"/content/drive/MyDrive/AIC/labeled_validation_dataset.jsonl\"\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "df = pd.read_json(file_path, lines=True)\n",
        "df.drop('example_id', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MBert Model**"
      ],
      "metadata": {
        "id": "j7en1-us_7mo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
        "from arabert.preprocess import ArabertPreprocessor\n",
        "\n",
        "model_name = \"malmarjeh/mbert2mbert-arabic-text-summarization\"\n",
        "preprocessor = ArabertPreprocessor(model_name=\"\")\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "pipeline = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "rXiaMvWGO9Ly",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b45e29bd-222f-487f-d5ab-6295bf42bf47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Model provided is not in the accepted model list. Preprocessor will default to a base Arabic preprocessor\n",
            "The following encoder weights were not tied to the decoder ['bert/pooler']\n",
            "The following encoder weights were not tied to the decoder ['bert/pooler']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **text summarize**"
      ],
      "metadata": {
        "id": "4D1d-dAu_4uv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_summary(text):\n",
        "    text = preprocessor.preprocess(text)\n",
        "\n",
        "    max_input_length = tokenizer.model_max_length - tokenizer.num_special_tokens_to_add(pair=True)\n",
        "    segments = [text[i:i + max_input_length] for i in range(0, len(text), max_input_length)]\n",
        "\n",
        "    generated_texts = []\n",
        "    for segment in segments:\n",
        "        result = pipeline(\n",
        "            segment,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            num_beams=3,\n",
        "            repetition_penalty=3.0,\n",
        "            max_length=200,\n",
        "            length_penalty=1.0,\n",
        "            no_repeat_ngram_size=3\n",
        "        )[0]['generated_text']\n",
        "        generated_texts.append(result)\n",
        "\n",
        "    result = \" \".join(generated_texts)\n",
        "    return result"
      ],
      "metadata": {
        "id": "9tq9CRD84Ijn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List to store summaries and references\n",
        "summaries = []\n",
        "references = []\n",
        "\n",
        "for sen in tqdm(df[\"paragraph\"][:3]):\n",
        "    summary_text = get_summary(sen)\n",
        "    summaries.append(summary_text)\n",
        "\n",
        "for reference in tqdm(df[\"summary\"]):\n",
        "    references.append(reference)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGoqHq5d3QzT",
        "outputId": "5ee3c400-56b3-41f2-93ca-4d04ca53541e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:102 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:102 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:102 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:102 for open-end generation.\n",
            " 33%|███▎      | 1/3 [00:32<01:05, 32.84s/it]Setting `pad_token_id` to `eos_token_id`:102 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:102 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:102 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:102 for open-end generation.\n",
            " 67%|██████▋   | 2/3 [00:59<00:29, 29.06s/it]Setting `pad_token_id` to `eos_token_id`:102 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:102 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:102 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:102 for open-end generation.\n",
            "100%|██████████| 3/3 [01:17<00:00, 25.98s/it]\n",
            "100%|██████████| 154/154 [00:00<00:00, 443628.31it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summaries[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pyk7IY6PWPu_",
        "outputId": "d913d487-c255-433a-8bf8-5a5a7f6a7e9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'دبلوماسيو الدولتين يطالبون بحملة تونس ضد الإجراء الفرنسي 15 دولة عربية تتعهد بالتزام \" الاحترام إزاء الإمبراطورية الشريفة \" المغرب يعلن عن موقفه من تثبيت فكرة \" تنحية السلطان الشرعي \" في المنطقة سلطة فرانكو'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "references[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "NFf3DTzQWQc1",
        "outputId": "719a75f5-4f50-4ad8-b029-6bf4e78fee21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'دبلوماسيو الدولتين لم يعترفوا بالعريضة التي قام الأعيان بتوقيعها, ومعارضة الدول العربية والآسيوية كانت تعتبر حملة شرسة ضد الإجراء الفرنسي عن طريق الصحافة, وقام علال الفاسي قال في إذاعة القاهرة عن تنحية السلطان وعائلته عن الوطن, والمعاهدة الذي حدثت بين البلدين كانت تنص بالتزام الإحترام للإمبراطورية الشريفة, وعملية تنصيب سلطان جديد على المغرب في أسبانيا أخذت الرفض.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Rouge**"
      ],
      "metadata": {
        "id": "2wRV8_Lq_y10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge import Rouge\n",
        "def calculate_rouge(reference, summary):\n",
        "    rouge = Rouge()\n",
        "    scores = rouge.get_scores(summary, reference)\n",
        "    return scores[0]"
      ],
      "metadata": {
        "id": "8geuy_3u6uj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# حساب مقاييس ROUGE\n",
        "rouge_scores = []\n",
        "\n",
        "for reference, summary in zip(references, summaries):\n",
        "    rouge_score = calculate_rouge(reference, summary)\n",
        "    rouge_scores.append(rouge_score)"
      ],
      "metadata": {
        "id": "yz7cP_8BPbY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rouge_scores[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_v9qeaGOGTey",
        "outputId": "c07db77d-8bcc-4409-c97d-8c0ffbe5578f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge-1': {'r': 0.20754716981132076, 'p': 0.34375, 'f': 0.25882352471695513},\n",
              " 'rouge-2': {'r': 0.07142857142857142,\n",
              "  'p': 0.11764705882352941,\n",
              "  'f': 0.08888888418765457},\n",
              " 'rouge-l': {'r': 0.16981132075471697, 'p': 0.28125, 'f': 0.21176470118754337}}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test**"
      ],
      "metadata": {
        "id": "ILx8T8RE_uJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"شهدت مدينة طرابلس، مساء أمس الأربعاء، احتجاجات شعبية وأعمال شغب لليوم الثالث على التوالي، وذلك بسبب تردي الوضع المعيشي والاقتصادي.\n",
        " واندلعت مواجهات عنيفة وعمليات كر وفر ما بين الجيش اللبناني والمحتجين استمرت لساعات،\n",
        " إثر محاولة فتح الطرقات المقطوعة، ما أدى إلى إصابة العشرات من الطرفين.\"\"\"\n",
        "\n",
        "test=get_summary(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RweduJ37_wX_",
        "outputId": "3e1eb0c7-8688-42e0-fbc5-8dac13170e9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:102 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "احتجاجات في طرابلس على خلفية مواجهات عنيفة بين الجيش اللبناني والمحتجين\n"
          ]
        }
      ]
    }
  ]
}